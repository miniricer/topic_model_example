{"cells":[{"cell_type":"markdown","id":"93403f85","metadata":{"id":"93403f85"},"source":["# 完全參考 [Word2Vec-以 gensim 訓練中文詞向量](https://www.kaggle.com/code/bbqlp33/word2vec-gensim/notebook) by [HONGTW](https://www.kaggle.com/bbqlp33)"]},{"cell_type":"code","execution_count":1,"id":"631ea4e8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"631ea4e8","executionInfo":{"status":"ok","timestamp":1704342226468,"user_tz":-480,"elapsed":24902,"user":{"displayName":"daucheng lyu","userId":"10574303180162034414"}},"outputId":"3a1cdf9b-e0fd-464b-ebd7-a17a6d65862e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting zhconv\n","  Downloading zhconv-1.4.3.tar.gz (211 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.6/211.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: zhconv\n","  Building wheel for zhconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for zhconv: filename=zhconv-1.4.3-py2.py3-none-any.whl size=208851 sha256=4b7f0b0ca5775ef0a41994ed28c261758ada87db2dc87a50f83dec6eb751d9a2\n","  Stored in directory: /root/.cache/pip/wheels/68/73/ff/95fe3e7b41a545b9701416c2178b920713b33022c3d605bdb4\n","Successfully built zhconv\n","Installing collected packages: zhconv\n","Successfully installed zhconv-1.4.3\n"]}],"source":["#安裝 簡轉繁 : zhconv\n","!pip install zhconv"]},{"cell_type":"markdown","id":"cc9b6c3b","metadata":{"id":"cc9b6c3b"},"source":["## 資料下載\n","*   [wiki 資料](https://dumps.wikimedia.org/zhwiki/latest/)\n","*  [zhwiki-latest-abstract-zh-tw3.xml.gz](https://dumps.wikimedia.org/zhwiki/latest/zhwiki-latest-abstract-zh-tw3.xml.gz)\n","*   [wget](https://eternallybored.org/misc/wget/1.21.4/64/wget.exe)"]},{"cell_type":"code","execution_count":null,"id":"c24143f9","metadata":{"id":"c24143f9"},"outputs":[],"source":["!wget.exe \"https://dumps.wikimedia.org/zhwiki/latest/zhwiki-latest-abstract-zh-tw3.xml.gz\""]},{"cell_type":"code","execution_count":3,"id":"198dbdac","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"198dbdac","executionInfo":{"status":"ok","timestamp":1704345770377,"user_tz":-480,"elapsed":15964,"user":{"displayName":"daucheng lyu","userId":"10574303180162034414"}},"outputId":"7b767124-507b-4b7f-a407-7d2655417364"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","gensim 4.3.2\n","jieba 0.42.1\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import gensim\n","import jieba\n","import zhconv\n","from gensim.corpora import WikiCorpus\n","from datetime import datetime as dt\n","from typing import List\n","\n","jieba.set_dictionary('/content/drive/MyDrive/Colab Notebooks/2024.01.05/model/dict.txt.big')\n","print(\"gensim\", gensim.__version__)\n","print(\"jieba\", jieba.__version__)"]},{"cell_type":"markdown","id":"42575047","metadata":{"id":"42575047"},"source":["# 1.中文文本前處理\n","在正式訓練 Word2Vec 之前，其實涉及了文本的前處理，本篇的處理包括如下三點 (而實務上對應的不同使用情境，可能會有不同的前處理流程):\n","\n","*   簡轉繁: zhconv\n","*   中文斷詞: jieba\n","*   停用詞\n","\n","## 簡繁轉換\n","wiki 文本其實摻雜了簡體與繁體中文，比如「数学」與「數學」，這會被 word2vec 當成兩個不同的詞。[1]\n","所以我們在斷詞前，需要加上簡繁轉換的手續"]},{"cell_type":"code","execution_count":4,"id":"311d67c2","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":38},"id":"311d67c2","executionInfo":{"status":"ok","timestamp":1704345779378,"user_tz":-480,"elapsed":310,"user":{"displayName":"daucheng lyu","userId":"10574303180162034414"}},"outputId":"6ddaf73f-cd3e-48f2-f15f-642e042f87b5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'這原本是一段簡體中文'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}],"source":["zhconv.convert(\"这原本是一段简体中文\", \"zh-tw\")"]},{"cell_type":"markdown","id":"1118c0a2","metadata":{"id":"1118c0a2"},"source":["## 中文斷詞\n","使用 jieba jieba.cut 來進行中文斷詞，\n","並簡單介紹 jieba 的兩種分詞模式:\n","\n","*   cut_all=False 精確模式，試圖將句子最精確地切開，適合文本分析；\n","*   cut_all=True 全模式，把句子中所有的可以成詞的詞語都掃描出來, 速度非常快，但是不能解決歧義；\n","而本篇文本訓練採用精確模式 cut_all=False"]},{"cell_type":"code","execution_count":5,"id":"0d546922","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0d546922","executionInfo":{"status":"ok","timestamp":1704345789718,"user_tz":-480,"elapsed":2566,"user":{"displayName":"daucheng lyu","userId":"10574303180162034414"}},"outputId":"f8083744-5d14-4a67-a955-996aab602281"},"outputs":[{"output_type":"stream","name":"stderr","text":["Building prefix dict from /content/drive/MyDrive/Colab Notebooks/2024.01.05/model/dict.txt.big ...\n","DEBUG:jieba:Building prefix dict from /content/drive/MyDrive/Colab Notebooks/2024.01.05/model/dict.txt.big ...\n","Dumping model to file cache /tmp/jieba.u37c832946ddec8ae58f75c2e8af3e98f.cache\n","DEBUG:jieba:Dumping model to file cache /tmp/jieba.u37c832946ddec8ae58f75c2e8af3e98f.cache\n","Loading model cost 2.273 seconds.\n","DEBUG:jieba:Loading model cost 2.273 seconds.\n","Prefix dict has been built successfully.\n","DEBUG:jieba:Prefix dict has been built successfully.\n"]},{"output_type":"stream","name":"stdout","text":["Full Mode: 我/ 来到/ 臺北/ 板橋/ 中華/ 中華電信/ 華電/ 電信\n","Default Mode: 我/ 来到/ 臺北/ 板橋/ 中華電信\n"]}],"source":["seg_list = jieba.cut(\"我来到臺北板橋中華電信\", cut_all=True)\n","print(\"Full Mode: \" + \"/ \".join(seg_list))  # 全模式\n","\n","seg_list = jieba.cut(\"我来到臺北板橋中華電信\", cut_all=False)\n","print(\"Default Mode: \" + \"/ \".join(seg_list))  # 精確模式"]},{"cell_type":"code","execution_count":6,"id":"f413a631","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f413a631","executionInfo":{"status":"ok","timestamp":1704345795482,"user_tz":-480,"elapsed":284,"user":{"displayName":"daucheng lyu","userId":"10574303180162034414"}},"outputId":"fdf69655-312c-4fb5-a510-3b58c941c90c"},"outputs":[{"output_type":"stream","name":"stdout","text":["['中', '英', '夾雜', '的', 'example', '，', 'Word2Vec', '應該', '很', 'interesting', '吧', '?']\n"]}],"source":["print(list(jieba.cut(\"中英夾雜的example，Word2Vec應該很interesting吧?\")))"]},{"cell_type":"markdown","id":"99ee97ea","metadata":{"id":"99ee97ea"},"source":["## 引入停用詞表\n","停用詞就是像英文中的 the,a,this，中文的你我他，與其他詞相比顯得不怎麼重要，對文章主題也無關緊要的，\n","是否要使用停用詞表，其實還是要看你的應用，也有可能保留這些停用詞更能達到你的目標。[1](http://zake7749.github.io/2016/08/28/word2vec-with-gensim/)\n","*   Is it compulsory to remove stop words with word2vec?（https://www.quora.com/Is-it-compulsory-to-remove-stop-words-with-word2vec）\n","*   The Effect of Stopword Filtering prior to Word Embedding Training（https://stats.stackexchange.com/questions/201372/the-effect-of-stopword-filtering-prior-to-word-embedding-training）"]},{"cell_type":"code","execution_count":null,"id":"95205496","metadata":{"id":"95205496"},"outputs":[],"source":["#!pip install spacy --user"]},{"cell_type":"code","execution_count":7,"id":"dedf59b1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dedf59b1","executionInfo":{"status":"ok","timestamp":1704345849931,"user_tz":-480,"elapsed":36022,"user":{"displayName":"daucheng lyu","userId":"10574303180162034414"}},"outputId":"4ddeaeda-9c08-4ead-f7ea-278aa19465d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('zh_core_web_sm')\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","--\n","\n","中文停用詞 Total=1891: ['且不说', '己', '曾经', '极其', '起初', '来讲', '呜', '来着', '［③⑩］', '哼唷', '理当', '遵照', '呼啦', '每个', '据悉', '⑥', '即令', '极', '除外', '不会'] ...\n","--\n","英文停用詞 Total=326: ['using', 'is', 'a', 'ca', 'while', 'used', 'thus', 'formerly', 'mine', 'serious', '‘ve', 'even', '‘ll', 'somewhere', 'no', 'thereby', 'me', 'thence', '‘re', 'hereafter'] ...\n"]}],"source":["import spacy\n","\n","# 下載語言模組\n","spacy.cli.download(\"zh_core_web_sm\")  # 下載 spacy 中文模組\n","spacy.cli.download(\"en_core_web_sm\")  # 下載 spacy 英文模組\n","\n","nlp_zh = spacy.load(\"zh_core_web_sm\") # 載入 spacy 中文模組\n","nlp_en = spacy.load(\"en_core_web_sm\") # 載入 spacy 英文模組\n","\n","# 印出前20個停用詞\n","print('--\\n')\n","print(f\"中文停用詞 Total={len(nlp_zh.Defaults.stop_words)}: {list(nlp_zh.Defaults.stop_words)[:20]} ...\")\n","print(\"--\")\n","print(f\"英文停用詞 Total={len(nlp_en.Defaults.stop_words)}: {list(nlp_en.Defaults.stop_words)[:20]} ...\")"]},{"cell_type":"code","execution_count":null,"id":"f96db34c","metadata":{"id":"f96db34c","outputId":"f0e67dbb-87a4-47eb-cb4e-812dd73a830d"},"outputs":[{"name":"stdout","output_type":"stream","text":["2222\n","3005\n"]}],"source":["STOPWORDS =  nlp_zh.Defaults.stop_words | \\\n","             nlp_en.Defaults.stop_words | \\\n","             set([\"\\n\", \"\\r\\n\", \"\\t\", \" \", \"\"])\n","print(len(STOPWORDS))\n","\n","# 將簡體停用詞轉成繁體，擴充停用詞表\n","for word in STOPWORDS.copy():\n","    STOPWORDS.add(zhconv.convert(word, \"zh-tw\"))\n","\n","print(len(STOPWORDS))"]},{"cell_type":"markdown","id":"27a2ea85","metadata":{"id":"27a2ea85"},"source":["# 讀取 wiki 語料庫，並且進行前處理和斷詞\n","維基百科 (wiki.xml.bz2)下載好後，先別急著解壓縮，因為這是一份 xml 文件，裏頭佈滿了各式各樣的標籤，我們得先想辦法送走這群不速之客，不過也別太擔心，gensim 早已看穿了一切，藉由調用 [wikiCorpus](https://radimrehurek.com/gensim/corpora/wikicorpus.html)，我們能很輕鬆的只取出文章的標題和內容。[1](http://zake7749.github.io/2016/08/28/word2vec-with-gensim/)"]},{"cell_type":"code","execution_count":null,"id":"0fc54467","metadata":{"id":"0fc54467"},"outputs":[],"source":["### 文字處理（斷詞+簡轉繁+stop word）\n","def preprocess_and_tokenize(\n","    text: str, token_min_len: int=1, token_max_len: int=15, lower: bool=True) -> List[str]:\n","    if lower:\n","        text  = text.lower()\n","    text = zhconv.convert(text, \"zh-tw\")\n","    return [\n","        token for token in jieba.cut(text, cut_all=False)\n","        if token_min_len <= len(token) <= token_max_len and \\\n","            token not in STOPWORDS\n","    ]"]},{"cell_type":"code","execution_count":null,"id":"baf51a8e","metadata":{"id":"baf51a8e","outputId":"0f50ce28-ea1b-4069-f385-d21d24f96734"},"outputs":[{"name":"stdout","output_type":"stream","text":["['歐幾', '裡得', '西元前', '世紀', '古希臘', '數學家', '幾何', '父', '此畫', '拉斐爾']\n","['來到', '臺北', '板橋', '中華電信']\n","['中', '英', '夾雜', 'example', 'ennn', 'word2vec', 'interesting', 'right']\n"]}],"source":["print(preprocess_and_tokenize(\"歐幾里得，西元前三世紀的古希臘數學家，現在被認為是幾何之父，此畫為拉斐爾\"))\n","print(preprocess_and_tokenize(\"我来到臺北板橋中華電信\"))\n","print(preprocess_and_tokenize(\"the 中英夾雜的example ennn... ，Word2Vec應該很interesting吧?, right?\"))"]},{"cell_type":"code","execution_count":null,"id":"12dc1f59","metadata":{"id":"12dc1f59"},"outputs":[],"source":["ZhWiki = \"0zhwiki-latest-abstract-zh-tw3.xml\"\n","print(f\"Parsing {ZhWiki}...\")\n","wiki_corpus = WikiCorpus(ZhWiki, tokenizer_func=preprocess_and_tokenize, token_min_len=1)"]},{"cell_type":"code","execution_count":null,"id":"c55678cb","metadata":{"id":"c55678cb"},"outputs":[],"source":["g = wiki_corpus.get_texts()\n","print(next(g)[:10])"]},{"cell_type":"markdown","id":"26906733","metadata":{"id":"26906733"},"source":["# 訓練 Word2Vec"]},{"cell_type":"code","execution_count":null,"id":"05fcdf83","metadata":{"id":"05fcdf83"},"outputs":[],"source":["from gensim.models import word2vec\n","import multiprocessing\n","\n","max_cpu_counts = multiprocessing.cpu_count()\n","word_dim_size = 300  #  設定 word vector 維度\n","print(f\"Use {max_cpu_counts} workers to train Word2Vec (dim={word_dim_size})\")\n","WIKI_SEG_TXT = \"data/wiki_seg.txt\"\n","\n","# 讀取訓練語句\n","sentences = word2vec.LineSentence(WIKI_SEG_TXT)\n","\n","# 訓練模型\n","model = word2vec.Word2Vec(sentences, size=word_dim_size, workers=max_cpu_counts)\n","\n","# 儲存模型\n","output_model = f\"word2vec.zh.{word_dim_size}.model\"\n","model.save(output_model)"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}